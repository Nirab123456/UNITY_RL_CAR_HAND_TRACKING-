# UNITY_RL_CAR_HAND_TRACKING-





https://github.com/Nirab123456/UNITY_RL_CAR_HAND_TRACKING-/assets/128963796/cacaad08-12cb-492b-bd36-3fc42d2d3ef6











https://github.com/Nirab123456/UNITY_RL_CAR_HAND_TRACKING-/assets/128963796/e49128d0-3387-4c33-ac7f-e3ee50612da7




Description:
This project, Unity Car Manipulation via MediaPipe or Computer Vision, merges computer vision and Unity to develop an interactive car manipulation experience using hand gestures. It is an interdisciplinary project combining Python, C#, and MediaPipe's hand-tracking technology to enable a user to manipulate virtual objects in Unity based on real-world hand movements captured through a webcam.

In this project, the Python component utilizes MediaPipe to detect hand landmarks via a webcam in real time. These hand gestures are then converted into commands that control objects within the Unity environment. The primary application developed in this project involves manipulating a car within the Unity game engine, allowing users to move and rotate the car or interact with other virtual objects without using traditional input devices like keyboards or game controllers.

Some technical highlights of the project include:

Real-Time Hand Detection: Using MediaPipe, the system tracks hand landmarks and recognizes gestures such as pointing, grabbing, or moving the hand in specific directions.
Unity Integration: The detected gestures are transmitted to Unity, where they control the virtual car, providing a seamless interaction between the real world and the game world.
Cross-Platform Development: The project involves integrating Python scripts for computer vision processing and C# scripts for object manipulation in Unity, offering a powerful example of how these technologies can work together.
The project demonstrates the potential of combining hand-tracking computer vision techniques with Unity for immersive, gesture-based interactions in virtual environments. It is ideal for applications in gaming, simulation, or even automotive design.

